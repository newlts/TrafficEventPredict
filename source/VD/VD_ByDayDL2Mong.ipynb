{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@vdid_1_@datacollecttime_1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "import xmltodict\n",
    "import os\n",
    "import pandas as pd\n",
    "import io\n",
    "import datetime\n",
    "import pymongo\n",
    "import json\n",
    "import gzip\n",
    "import dns\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "urlBase='https://tisvcloud.freeway.gov.tw/history/vd/'  # 20190624/cms_value_0000.xml.gz   20190624/cms_value_0014.xml.gz\n",
    "baseDir='../../../data/'\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client.traffic\n",
    "trType='vd'\n",
    "#建立 unique index 以防重複 insert doc to mongodb, 並且加速查詢, 如果同樣的 compound unique index已經存在則不作用\n",
    "db['vd1'].create_index([(\"@vdid\",1),(\"@datacollecttime\",1)],unique=True)\n",
    "db['vd5'].create_index([(\"@vdid\",1),(\"@datacollecttime\",1)],unique=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#確認該 url 是否可以下載, 例如 20190230 就不存在, 無法下載; 而且必須是附件形式的方可\n",
    "def isDownloadable(url):\n",
    "    \"\"\"\n",
    "    Does the url contain a downloadable resource\n",
    "    \"\"\"\n",
    "    h = requests.head(url, allow_redirects=True)\n",
    "    header = h.headers\n",
    "    content_type = header.get('content-type')\n",
    "    if content_type is None:\n",
    "        return False\n",
    "    if 'text' in content_type.lower():\n",
    "        return False\n",
    "    if 'html' in content_type.lower():\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下載某url檔案後, 放在指定目錄下\n",
    "def downloadFileFromUrl(url, directory):\n",
    "    filename = directory+'/'+ url.rsplit('/', 1)[1]\n",
    "    if not os.path.exists(filename):\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open(filename, 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#抓取 CMS 的某一天每1分鐘一次 所有檔案 並下載到指定目錄\n",
    "def downloadVD1MinDay(trType, day, baseDir):\n",
    "    downloads=[]\n",
    "    for hour in range(0,24):\n",
    "        for mininute in range(0,60,1):  #vd 每5分鐘一次\n",
    "            downloads.append(urlBase + day + '/' + trType + '_value_'+ format(hour, '02d')+ format(mininute, '02d') +'.xml.gz' )\n",
    "    p=baseDir+trType+'1Min'+'/'+day\n",
    "    Path(p).mkdir(parents=True, exist_ok=True)\n",
    "    for url in downloads:\n",
    "        if isDownloadable(url):\n",
    "            downloadFileFromUrl(url,p)\n",
    "            #print(url)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#抓取 CMS 的某一天每5分鐘一次 所有檔案 並下載到指定目錄\n",
    "def downloadVD5MinDay(trType, day, baseDir):\n",
    "    downloads=[]\n",
    "    for hour in range(0,24):\n",
    "        for mininute in range(0,60,5):  #vd 每5分鐘一次\n",
    "            downloads.append(urlBase + day + '/' + trType + '_value5_'+ format(hour, '02d')+ format(mininute, '02d') +'.xml.gz' )\n",
    "    p=baseDir+trType+'/'+day\n",
    "    Path(p).mkdir(parents=True, exist_ok=True)\n",
    "    for url in downloads:\n",
    "        if isDownloadable(url):\n",
    "            downloadFileFromUrl(url,p)\n",
    "            #print(url)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertFiles2Mongo(files, directory):\n",
    "    if OneMinute:\n",
    "        collect=db['vd1']\n",
    "    else:    \n",
    "        collect=db['vd5']\n",
    "    i=1\n",
    "    for file in files:\n",
    "        insertFile2Mongo(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "insertFile2Mongo(file, directory):        \n",
    "    print(i,directory,file)\n",
    "    i += 1\n",
    "    f = gzip.open(directory+file, 'rb')\n",
    "    doc = xmltodict.parse(f)\n",
    "    Y=doc['XML_Head']['Infos']\n",
    "    if Y is not None:\n",
    "        X=Y['Info']\n",
    "        #has datacollecttime, no need updateTime=datetime.datetime.strptime(doc['XML_Head']['@updatetime'], \"%Y/%m/%d %H:%M:%S\")\n",
    "        json_data = json.dumps(X)\n",
    "        cc = json.loads(json_data)\n",
    "        tmpDF=pd.DataFrame(cc)\n",
    "        tmpDF['@datacollecttime']=tmpDF['@datacollecttime'].apply(lambda x:datetime.datetime.strptime(x, \"%Y/%m/%d %H:%M:%S\"))\n",
    "        tmpDF['lane']=tmpDF['lane'].apply(splitLane2DF)\n",
    "        #print(tmpDF['lane'][0],'\\n',tmpDF['lane'][1],'\\n',tmpDF['lane'][2],'\\n',tmpDF['lane'][3])\n",
    "        #a=cc[1]\n",
    "        #print(a['@vdid'],a['@datacollecttime'],a['@status'],'\\n',splitLane2DF(a['lane'])) \n",
    "        records = tmpDF.to_dict('records')\n",
    "        try:\n",
    "            collect.insert_many(records)\n",
    "        except Exception as err:\n",
    "            print (\"collect.insert_many ERROR:\", err)    \n",
    "    else:\n",
    "        print('TypeError: ',Y)\n",
    "\n",
    "    f.close()\n",
    "    ######3##########TODO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "def downnload1HourFiles2Mongo(trType, day, hour, baseDir, OneMinute=True):\n",
    "    downloads=[]\n",
    "    p=baseDir+trType+'1Min'+'/'+day+'/'\n",
    "    if OneMinute:\n",
    "        for mininute in range(0,60,1):  #vd 每1分鐘一次\n",
    "            downloads.append(urlBase + day + '/' + trType + '_value_'+ format(hour, '02d')+ format(mininute, '02d') +'.xml.gz' )\n",
    "        Path(p).mkdir(parents=True, exist_ok=True)\n",
    "    else:\n",
    "        for mininute in range(0,60,5):  #vd 每1分鐘一次\n",
    "            downloads.append(urlBase + day + '/' + trType + '_value5_'+ format(hour, '02d')+ format(mininute, '02d') +'.xml.gz' )\n",
    "        p=baseDir+trType+'5Min'+'/'+day+'/'\n",
    "        Path(p).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for url in downloads:\n",
    "        if isDownloadable(url):\n",
    "            downloadFileFromUrl(url,p)\n",
    "            \n",
    "            insertFiles2Mongo([os.path.basename(urlparse(url).path)], p, True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import json_normalize #package for flattening json in pandas df\n",
    "\n",
    "def splitLane2DF(lanes):\n",
    "    tmpDF=json_normalize(data=lanes, record_path='cars', meta=['@vsrid', '@speed','@laneoccupy'])\n",
    "    records = tmpDF.to_dict('records')\n",
    "    return records\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "          \n",
    "def getAllFiles2Mongo(trType, day, baseDir):\n",
    "    directory=baseDir+day+'/'\n",
    "    collect = db['vd20']\n",
    "    \n",
    "    files = [f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "    insertFiles2Mongo(files, directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download5MinInsert(trType, day, baseDir):\n",
    "    downloadVD5MinDay(trType, day, baseDir)\n",
    "    getAllFiles2Mongo(trType, day, baseDir, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#days=['0405','0406','0407','0606','0607','0608'] #,'0624','0625','0626','0627','0628','0202','0203','0204','0205','0206','0207','0208','0209','0210']#\n",
    "#days=['1010','1011','1012','1013','0913','0914','0915']\n",
    "days=['0322','1210','1218']#,'0307']\n",
    "for d in days:\n",
    "    #downloadVD5MinDay('vd','2019'+d,baseDir)\n",
    "    getAllFiles2Mongo('vd','2019'+d,baseDir, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download1MinInsert(trType, day, baseDir):\n",
    "    downloadVD1MinDay(trType, day, baseDir)\n",
    "    getAllFiles2Mongo(trType, day, baseDir, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days=['0322'] #,'1210','1218']#,'0307']\n",
    "for d in days:\n",
    "    download1MinInsert('vd','2019'+d,baseDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ../../../data/vd1Min/20191218/ vd_value_2200.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2201.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2202.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2203.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2204.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2205.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2206.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2207.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2208.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2209.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2210.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2211.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2212.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2213.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2214.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2215.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2216.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2217.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2218.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2219.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2220.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2221.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2222.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2223.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2224.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2225.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2226.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2227.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2228.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2229.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2230.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2231.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2232.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2233.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2234.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2235.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2236.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2237.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2238.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2239.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2240.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2241.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2242.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2243.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2244.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2245.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2246.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2247.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2248.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2249.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2250.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2251.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2252.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2253.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2254.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2255.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2256.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2257.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2258.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2259.xml.gz\n"
     ]
    }
   ],
   "source": [
    "downnload1HourFiles2Mongo('vd', '20191218', 22, baseDir, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ../../../data/vd1Min/20191218/ vd_value_2300.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2301.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2302.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2303.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2304.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2305.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2306.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2307.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2308.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2309.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2310.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2311.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2312.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2313.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2314.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2315.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2316.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2317.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2318.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2319.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2320.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2321.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2322.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2323.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2324.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2325.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2326.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2327.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2328.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2329.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2330.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2331.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2332.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2333.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2334.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2335.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2336.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2337.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2338.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2339.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2340.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2341.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2342.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2343.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2344.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2345.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2346.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2347.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2348.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2349.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2350.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2351.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2352.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2353.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2354.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2355.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2356.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2357.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2358.xml.gz\n",
      "1 ../../../data/vd1Min/20191218/ vd_value_2359.xml.gz\n"
     ]
    }
   ],
   "source": [
    "downnload1HourFiles2Mongo('vd', '20191218', 23, baseDir, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
